# OnDeviceTranscriber Architecture

> Last updated: January 2025

## Project Overview

OnDeviceTranscriber is a minimalist multiplatform (iOS + macOS) audio transcription app with **Shortcuts integration as a core feature**. It uses WhisperKit for on-device transcription with excellent Portuguese Brazilian accuracy.

### Why This Project Exists

Apple's native Speech Framework has poor accuracy for Portuguese (~8% WER vs ~1-2% WER for Whisper). WhisperKit brings OpenAI's Whisper models to run directly on Apple Silicon.

---

## Configuration Constants

These values are defined in `Services/WhisperService.swift` and can be easily adjusted:

```swift
enum TranscriptionConfig {
    // Voice Activity Detection (VAD) - In-App UI
    static let silenceThreshold: Float = 0.01          // Audio level considered "silence"
    static let silenceDurationToStop: TimeInterval = 3.0  // Seconds of silence before auto-stop
    static let maxRecordingDuration: TimeInterval = 300   // 5 minutes max

    // Voice Activity Detection (VAD) - Background Shortcuts
    static let backgroundSilenceThreshold: Float = 0.01
    static let backgroundSilenceDuration: TimeInterval = 5.0  // â† ITERATE ON THIS
    static let backgroundMaxDuration: TimeInterval = 300

    // Model settings
    static let defaultModel = "small"                  // Options: tiny, small, distil-large-v3
    static let defaultLanguage = "pt"                  // Portuguese Brazilian

    // Audio settings
    static let sampleRate: Int = 16000                 // WhisperKit expects 16kHz
}
```

**To iterate on background VAD behavior:** Adjust `backgroundSilenceDuration` (currently 5 seconds).
The longer duration allows natural pauses while speaking without triggering auto-stop.

---

## Architectural Decisions

### 1. Service Layer: Singleton Pattern

**Decision:** `WhisperService` uses a shared singleton instance.

**Rationale:**
- WhisperKit model loading is expensive (~500MB+ memory, several seconds)
- Both the app UI and App Intents need access to the same loaded model
- Singleton ensures model loads once, reused everywhere
- Prevents duplicate memory usage

```swift
@MainActor
final class WhisperService: ObservableObject {
    static let shared = WhisperService()
    // ...
}
```

### 2. Recording Modes

| Context | Mode | Behavior |
|---------|------|----------|
| **In-App UI** | Manual | User taps Record â†’ speaks â†’ taps Stop. No time limit. |
| **Background Shortcuts** | VAD + Audio Feedback | ğŸ”Š Beep on start â†’ speaks â†’ 5s silence â†’ ğŸ”Š Beep on stop â†’ transcribe |

**Background Shortcuts Flow:**
1. User triggers Shortcut (Action Button, Siri, widget)
2. Stays in current app (no UI switch)
3. Hears start beep + haptic feedback
4. Speaks naturally
5. After 5 seconds of silence, hears stop beep + haptic
6. Transcription happens, text returns to Shortcuts

**Rationale:** Background shortcuts have no UI, so audio/haptic feedback tells user when recording starts/stops.

### 3. Model Download Strategy

**Decision:** Force download on first app launch with progress UI.

**Rationale:**
- Ensures model is ready when user first tries to transcribe
- Prevents frustrating delays during actual usage
- App Intents can assume model is available (with fallback check)

**Implementation:**
- `OnDeviceTranscriberApp.swift` checks if model exists on launch
- Shows blocking download progress view if not downloaded
- Stores model in app container (persists across launches)

### 4. Default Language

**Decision:** Default to Portuguese Brazilian (`pt`).

**Rationale:** Primary use case is Portuguese transcription. Auto-detect available as option.

### 5. Platform Handling

**Decision:** Single target with conditional compilation.

| Aspect | iOS | macOS |
|--------|-----|-------|
| Audio Session | `AVAudioSession` configuration required | Not needed |
| Permissions | Runtime request dialogs | Sandbox entitlements |
| UI Layout | Compact, touch-optimized | Larger, click-optimized |

```swift
#if os(iOS)
// iOS-specific code
#elseif os(macOS)
// macOS-specific code
#endif
```

### 6. App Intent Architecture

**Decision:** Intent uses `WhisperService.shared` directly.

```
Shortcuts App                    OnDeviceTranscriber
     â”‚                                   â”‚
     â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    invoke    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Shortcut â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶  â”‚   TranscribeIntent   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚                      â”‚
                          â”‚  1. Check model      â”‚
                          â”‚  2. Record/load audioâ”‚
                          â”‚  3. Transcribe       â”‚
                          â”‚  4. Return text      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚ WhisperService.sharedâ”‚
                          â”‚                      â”‚
                          â”‚  - Already loaded    â”‚
                          â”‚  - Same instance as  â”‚
                          â”‚    app UI uses       â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Benefits:**
- If user opens app first, model is pre-loaded for Intent
- No duplicate model loading
- Consistent transcription settings

---

## Project Structure

```
OnDeviceTranscriber/
â”œâ”€â”€ OnDeviceTranscriber.xcodeproj/
â”œâ”€â”€ OnDeviceTranscriber/
â”‚   â”œâ”€â”€ App/
â”‚   â”‚   â””â”€â”€ OnDeviceTranscriberApp.swift     # App entry point, model download check
â”‚   â”œâ”€â”€ Views/
â”‚   â”‚   â”œâ”€â”€ ContentView.swift                # Main transcription screen
â”‚   â”‚   â”œâ”€â”€ RecordButton.swift               # Animated record/stop button
â”‚   â”‚   â””â”€â”€ TranscriptionResultView.swift    # Text display with copy
â”‚   â”œâ”€â”€ ViewModels/
â”‚   â”‚   â””â”€â”€ TranscriptionViewModel.swift     # UI state management
â”‚   â”œâ”€â”€ Services/
â”‚   â”‚   â”œâ”€â”€ WhisperService.swift             # Core: WhisperKit + recording
â”‚   â”‚   â””â”€â”€ AudioRecorderService.swift       # AVAudioEngine wrapper
â”‚   â”œâ”€â”€ Models/
â”‚   â”‚   â”œâ”€â”€ TranscriptionResult.swift        # Transcription output model
â”‚   â”‚   â””â”€â”€ TranscriptionError.swift         # Custom error types
â”‚   â”œâ”€â”€ Intents/
â”‚   â”‚   â”œâ”€â”€ TranscribeIntent.swift           # AppIntent for Shortcuts
â”‚   â”‚   â””â”€â”€ AppShortcuts.swift               # Suggested shortcuts
â”‚   â”œâ”€â”€ Utilities/
â”‚   â”‚   â””â”€â”€ PlatformHelpers.swift            # Platform-specific helpers
â”‚   â””â”€â”€ Assets.xcassets/
â”œâ”€â”€ ARCHITECTURE.md                          # This file
â””â”€â”€ README.md
```

---

## Data Flow

### In-App Transcription Flow

```
User taps Record
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ViewModel starts â”‚
â”‚ AudioRecorder   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     User taps Stop
â”‚ Recording...    â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ (accumulating   â”‚                      â”‚
â”‚  audio buffer)  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WhisperService  â”‚
â”‚ .transcribe()   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TranscriptionResult â”‚
â”‚ displayed in UI â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Shortcuts Transcription Flow

```
Shortcut triggered (Siri, widget, etc.)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TranscribeIntent    â”‚
â”‚ .perform()          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Audio file provided?â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚ Yes     â”‚ No
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Use    â”‚  â”‚ Start recording â”‚
â”‚ file   â”‚  â”‚ with VAD        â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                â”‚
    â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚       â”‚ Wait for 3s     â”‚
    â”‚       â”‚ silence or 5min â”‚
    â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WhisperService      â”‚
â”‚ .transcribe()       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Return text to      â”‚
â”‚ Shortcuts           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Error Handling Strategy

| Error Type | User Message | Recovery |
|------------|--------------|----------|
| Model not downloaded | "Downloading transcription model..." | Auto-download with progress |
| Microphone permission denied | "Microphone access required" | Open Settings button |
| Recording failed | "Could not access microphone" | Retry button |
| Transcription failed | "Transcription failed. Please try again." | Retry button |
| No speech detected | "No speech detected in audio" | Informational, allow retry |

---

## Future Enhancements (Not in v1.0)

- [ ] Model selection UI (tiny/small/distil-large-v3)
- [ ] Language selection UI
- [ ] Real-time streaming transcription
- [ ] Audio waveform visualization
- [ ] Transcription history
- [ ] Export options (text file, share sheet)
- [ ] Widget for quick recording

---

## Technical Constraints

| Constraint | Value | Rationale |
|------------|-------|-----------|
| Min iOS | 26.0 | Latest platform features |
| Min macOS | 15.7 | Apple Silicon optimized |
| Model size | < 750MB | Balance accuracy vs storage |
| Memory | < 2GB runtime | Fit on 6GB devices |
| Transcription speed | < 2x realtime | Acceptable UX |

---

## Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| WhisperKit | main branch | On-device Whisper inference |
| swift-transformers | 1.1.6 | ML model support |
| swift-collections | 1.3.0 | Data structures |

---

## Testing Checklist

### App UI
- [ ] First launch shows model download progress
- [ ] Record button shows visual feedback
- [ ] Transcription appears after recording
- [ ] Copy button works
- [ ] Works on iOS and macOS

### Shortcuts Integration
- [ ] "Transcribe Audio" appears in Shortcuts app
- [ ] Recording from microphone works
- [ ] Audio file input works
- [ ] Text output chains to next action
- [ ] Works on iOS and macOS

### Edge Cases
- [ ] No speech in recording â†’ appropriate message
- [ ] Very long recording (5+ min) â†’ handled gracefully
- [ ] Permission denied â†’ clear error message
- [ ] Model not ready â†’ blocks with feedback
